## Introduction

- Human tutors can produce extremely large learning gains (Bloom 1984)
- Intelligent Tutoring Systems (ITS) behave fundamentally in similar ways
- A "Task" is an activity (on scale of minutes). A Task consists of multiple "Steps"
- A "Step" is a single (recorded) UI interaction. Note that things such as clicking on "Save" button is not a "Step". In a more Cog. Sci. p.o.v, a Step is a single cognitive action/process, such as assigning a variable, writing a response, etc.
- Task domain is the information and skills to be taught
- A Learning Event is the construction or application of a knowledge component (scheme/sign). These are un-observable events whereas Steps are observable. These are not just accomadations or internalisation, but rather acquiring temporary information, such as the value of a quantity from a problem, given data, hints, etc.
- Outer Loop is an iteration over tasks
- Inner Loop is an iteration over steps
- Anything "Incorrect" is just something that is inconsistent with the instructional objectives (even "irrelevant" is categorised as "incorrect")
- Some ITS built in the past:
  - Algebra cognitive tutor
  - Andes (numericals in college physics)
  - AutoTutor (qualitative problem solving)
  - Sherlock (avionic electronic equipment on-the-job training)
  - **SQL-Tutor** (constructing SQL queries to given database)
  - Steve (Operative equipment)
- Techniques for establishing the knowledge components that the student has are :
  - Transfer experiments
  - Predicting Learning Curve : Given the time taken or difficulty faced for the past learning events for a particular knowledge component (concept), one can predict (using the learning curve) how much time the next learning event for the same component will take.
- The main duty of the outer loop is to select the next task for the student that falls in his/her ZPD
- The inner loop is for steps. For example, in Andes, the algorithm for inner loop has 3 stages
  - [OPTIONAL] Tutor gives a hint
  - Student does a step
  - Tutor gives immediate feedback on the step (and records it or extracts info from it)
- Systems that lack an inner loop are called Computer-Aided Instruction (CAI), Computer Based Training (CBT), Web-Based Homework (WBH), etc... but not ITS.

## The outer loop

### Task Selection

The various basic ways for task selection (simplest to complex) are

1. Simple Menu: Here, there is no sequencing, no recommendation, nothing .. The student and the instructor (if student is in a class) are free to choose the next task
2. Fixed Sequence: Here, there is sequencing, but it's not adaptive. The probability that the tasks are in student's ZPD is increased.
3. Mastery Learning: Break the course into units/levels with increasing difficulty. Keep assigning tasks to the student from one level till he has mastered all knowledge components (reported by inner loop or by score) and then allow moving to next unit. 
4. Macroadaptation: Maintain a vector to proficiency in required knowledge components for the student. For each task, also have a vector of level of proficiency required in different knowledge components to do it. The tasks whose vectors align well with the student's vector, are in the ZPD and can be assigned. Some ITS also involve incorrect knowledge components. If a task is known to remedy the misconcept, then it will be assigned. Some ITS also model student preferences (visual vs verbal explanations, etc.) to choose tasks that are compatible with student's style of learning. The total information about the student is called a "Student Model". This is stored persistently (not as a session variable).

Some ITS also allow for different modes of doing the task (this is what we are interested in)
The three main modes are
- Worked Examples
- Structuring via hints (socratic tutoring falls here)
- Productive Failure

The usual practice is to start with the most guided mode (worked example) and slowly fade away the scaffolding.

When a course is complex, we can model it as a dependency tree of concepts.
Each level of this tree can have a different task selection policy.

There is field of AI called "Planning" according to which, the macroadaptive loop is a simple reactive agent. More complex, plane based agents are not yet there in ITS.

### Task Generation

#### Problem Generators

Ideally the tutor should be able to generate tasks on its own. For example, the SQL-Tutor generates SQL queries that involve target knowledge components. The problem statement that has this SQL query as solution is generated by a human; which is a limitation of AI, not of the design.

#### Authoring tools

Here, the question is first designed by a human, and the way to solve it is either figured out be the ITS itself or learnt via a demonstration (possibly doable with Blender). The tool then generalises the solution, adds variation and asks the problem setter (author) to verify its correctness

## The Inner Loop

The ITS provides _services_ to the student such as

### Minimal Feedback : 

Only indicating whether step is 
  - correct
  - incorrect
  - non-optimal
  - unrecognisable (by the tutor)
  This feedback can be immediate, delayed or on-request.

### Hints on the next step

- The _timing_ of the hint is usually _predicted_ (It's not on-demand to avoid help abuse and help refusal). The DT tutor for example, uses "decision theory" to predict student's reaction to different actions (hints) by the tutor.
- The _choice_ of hint is done mainly using policies such as (in decreasing priority):
  - The hinted step must be correct
  - The hint must not have been already given before.
  - The hint may align with instructor's prefered path of solving
  - The hint may fulfill on the student's plan to do the task. Here, the ITS must also dynamically re-construct the plan that the student seems to be following.
- The way of hinting is how much of the next step is revealed. 
  - Pointing hints are where you only point to a part of a question that could trigger recall or an ah-ha moment
  - Teaching hint is giving a fact (theorem, algorithm, etc.) in an abstract and detached manner that is pivotal.
  - Reasoning hint is when you give the fact in a concrete (in-context) manner.
  - Bottom out hinting is directly intructing what the next step is.

  Usually, a hint sequence consisting of less to more revealing hints is generated. 
  Also, for each hint, the knowledge components used for generating it are recorded.
  It is favourable to have a single knowledge component per hint. If that's not possible, just give a bottom-out hint.

### Error-specific Feedback

Qualitative feedback that explains why the step is wrong.

On each incorrect step, the first thing done is generating an _error description_ which consists of 
1. what category of error was made (arithmetic error, wrong formula application, wrong concept, wrong vocabulary, etc.), as well
2. A textual description of the error, containing all necessary components for analysis. For example, for an algebra step, you might have the original equation and the new equation. This textual description is generated by filling text templates with values in the step. The text templates are specific to the category of error.

Here, you can again use hint sequences for feed-back. Not that before, we discussed hints for the next step. Here, it's hints for an incorrect step.

The hint sequence goes from pointing the mistake that the student made in the step to telling the correct setp.

Again, each hint should have correction for only one mistake in the step at a time.
A pointing hint for example, only redirects student's attention to a slip up or misconception. In that case, it makes sense to only point out one mistake at a time and let the student re-examine the step by himself and re-do the step. If in the re-attempt there are still mistakes, just do the hinting again. 

### Assessment of knowledge

- A fine grain assessment quantifies competence in each knowledge concept, assigning a number to each. These are used for small tutoring decisions such as what to teach next or what to hold a help session on.
- A coarse grain assessment quantifies the overall competence, with a single number. These are used for big decision such as grading, assigning pass or fail, replanning, etc.

We are mainly interested in fine grained assessment since our applicaion depends on it deeply. There are many ways of doing it.

#### Counting learning events

Each step usually has multiple learning events (sub-steps). The step analyser can predict the learning events that the student might have taken. Then, for each  learning event, it increments the counter for the corresponding knowledge component. 

The "mastery" of the knowledge compoent related to that learning event is then, the number of times than the counter divided by the number of times the learning event should've occured.

Since there can be multiple interpretations/predictions, we need a better way than just going with the most probable interpretation of a step. This is called the _assignment of credit_ problem.

This is done using Bayesian networks and techniques from Uncertaity AI (UAI).

Another method to define mastery could be using a EWMA rather than simple fraction.
One must also look at the deviation in the mastery. For example, a master of 1/2 with just 2 expected learning events vs mastery of 1/2 with 100 expected learning events (50 successful) are different.

Often some learning events for a concept are more difficult than others. In that case, it would be wrong to weigh both the same way. We should use something known are the Item Response Theory (IRT) instead.

Moreover, the matery for different knowledge concepts is not independent, so just changing mastery for one knowledge concept is not good enough.

### Review/Verification of solution

I am not doing this, since this isn't part of the project. 

But the idea is that control strategies are not learnt effectively with per-step feedback and it might be better to withhold the feedback all the way till the end of time/task to invoke productive failure for control strategies.